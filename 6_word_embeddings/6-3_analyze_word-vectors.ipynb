{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.manifold import TSNE\n",
    "from gensim.models.fasttext import FastText as FT_gensim\n",
    "import pandas as pd\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import figure, show, output_file, save\n",
    "from bokeh.models import ColumnDataSource, LabelSet, Legend, LegendItem, Range1d #, HoverTool, CustomJS, , Slider\n",
    "from bokeh.layouts import column\n",
    "from bokeh.palettes import all_palettes\n",
    "from bokeh.palettes import Category20\n",
    "output_notebook()\n",
    "# note: more recent bokeh versions require notebook 5 or JupyterLab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Vectors in Gensim\n",
    "For the code see https://stackoverflow.com/questions/27139908/load-precomputed-vectors-gensim\n",
    "The advantage of loading in gensim is that we can use existing functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import figure, show, output_file, save\n",
    "from bokeh.models import ColumnDataSource, LabelSet, Legend, LegendItem, Range1d #, HoverTool, CustomJS, , Slider\n",
    "from bokeh.layouts import column\n",
    "from bokeh.palettes import all_palettes\n",
    "from bokeh.palettes import Category20\n",
    "output_notebook()\n",
    "# note: more recent bokeh versions require notebook 5 or JupyterLab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"output/vec_file.txt\"\n",
    "model = gensim.models.keyedvectors.Word2VecKeyedVectors.load_word2vec_format(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_categories(model, words, topn=10):\n",
    "    \"\"\"word_categories takes an iterable with one or more words from the vocabulary of model.\n",
    "    For each word a dictionary of similar words (with the target word) is construed.\n",
    "    The value of each word is numerical (integer) and indicates the category to which it belongs.\n",
    "    The function returns a dictionary.\"\"\"\n",
    "    word_d = {}\n",
    "    for idx, word in enumerate(words):\n",
    "        w = model.wv.most_similar(word, topn=topn)\n",
    "        w = [m[0] for m in w]\n",
    "        w.append(word)\n",
    "        for item in w:\n",
    "            if item in word_d:\n",
    "                word_d[item] = len(words)\n",
    "            else:\n",
    "                word_d[item] = idx\n",
    "    return word_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project and Visualize Related Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_bokeh(model, word_d, words, fontsize=\"12pt\"):\n",
    "\n",
    "    labels = []\n",
    "    tokens = []\n",
    "    categories = []\n",
    "    legend = []\n",
    "    \n",
    "    for word in word_d:\n",
    "        tokens.append(model.wv[word])\n",
    "        labels.append(word)\n",
    "        categories.append(word_d[word])\n",
    "        if word_d[word] == len(words): \n",
    "            legend.append(\"mixed\")\n",
    "        else: \n",
    "            legend.append(words[word_d[word]])\n",
    "    \n",
    "    color_d = {0: \"black\", 1: \"red\", 2: \"green\", 3: \"yellow\", 4: \"brown\", 5: \"blue\"}\n",
    "    colors = [color_d[category] for category in categories]\n",
    "    #c = Category20[len(words) + 1]\n",
    "    #colors = [c[category] for category in categories]\n",
    "    \n",
    "    tsne = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
    "    tsne_embedding = tsne.fit_transform(tokens)\n",
    "    tsne_embedding = pd.DataFrame(tsne_embedding, columns=['x','y'])\n",
    "    tsne_embedding[\"color\"] = colors\n",
    "    tsne_embedding[\"labels\"] = labels\n",
    "    tsne_embedding[\"legend\"] = legend\n",
    "\n",
    "    source = ColumnDataSource(\n",
    "        data=dict(\n",
    "        x = tsne_embedding.x,\n",
    "        y = tsne_embedding.y,\n",
    "        colors = tsne_embedding.color,\n",
    "        labels=tsne_embedding.labels,\n",
    "        legend = tsne_embedding.legend\n",
    "        )\n",
    "    )\n",
    "\n",
    "    l = LabelSet(x='x', y='y', text='labels', level='glyph',\n",
    "              x_offset=5, y_offset=5, source=source, render_mode='canvas', \n",
    "             text_font_size=fontsize, text_font=\"CuneiformComposite\")\n",
    "\n",
    "    plot_tsne = figure(plot_width=900, plot_height=900) #, tools=tools_tsne, title='Papers')\n",
    "    plot_tsne.circle('x', 'y', size=7, fill_color='colors', \n",
    "                  line_alpha=0, line_width=0.01, source=source, legend_label=\"legend\")\n",
    "    plot_tsne.add_layout(l)\n",
    "    plot_tsne.legend.border_line_width = 3\n",
    "    plot_tsne.legend.border_line_color = \"black\"\n",
    "    plot_tsne.legend.border_line_alpha = 1\n",
    "    plot_tsne.legend.location = \"top_right\"\n",
    "    plot_tsne.legend.background_fill_color = \"beige\"\n",
    "    plot_tsne.legend.background_fill_alpha = 0.5\n",
    "    show(plot_tsne)\n",
    "    return plot_tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_file(\"graphs/vegetables_perfumes.html\")\n",
    "vegetables_perfumes = [\"Å¡imgig[tree]N\", \"hiz[vegetable]N\"]\n",
    "words_d = word_categories(model, vegetables_perfumes, 35)\n",
    "p2 = tsne_bokeh(model, words_d, vegetables_perfumes, \"12pt\")\n",
    "#save(p2)\n",
    "#show(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
